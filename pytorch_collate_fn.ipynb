{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_collate_fn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYNGwlt6wxRfsUb3Zs5ZVg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KIHOON71/pytorch_tutorial/blob/main/pytorch_collate_fn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collatae function\n",
        "\n",
        "- Dataloader는 기본적으로 자동적으로 batch_size를 파라미터로 받아서 collate를 실행한다.\n",
        "- 기본적으로 default collate 함수는 기본적으로 데이터들이 어떤 데이터의 타입으로 반환하는가를 확인하고, batch 를 (x_batch, y_batch)로 묶으려고 한다.\n",
        "- 그러나 데이터 타입에 따라 기본적인 collate함수를 사용할 수 없으면, 우리는 커스텀하여 사용할 수 있다."
      ],
      "metadata": {
        "id": "Db5Axf93ID9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예시"
      ],
      "metadata": {
        "id": "jvUFqE1UJPZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "uhz-69KjJbIc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = ['No man is an island','Entire of itself',\n",
        "'Every man is a piece of the continent','part of the main',\n",
        "'If a clod be washed away by the sea','Europe is the less',\n",
        "'As well as if a promontory were','As well as if a manor of thy friend',\n",
        "'Or of thine own were','Any man’s death diminishes me',\n",
        "'Because I am involved in mankind',\n",
        "'And therefore never send to know for whom the bell tolls',\n",
        "'It tolls for thee']\n",
        "\n",
        "labels = [random.randint(0,1) for i in range(len(reviews))]\n",
        "\n",
        "dataset = list(zip(reviews, labels))\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "  for text, label in data_iter:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(iter(dataset)), specials = ['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))"
      ],
      "metadata": {
        "id": "3yzYjkJGJSPe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위와 같은 경우에 custom collate 함수가 사용될수 있다. 시퀀셜 데이터 중 가장 긴 길이에 맞춰 padding을 집어 넣기 위해라던지. \n",
        "- collate 함수는 매 번 데이터 샘플의 리스트와 함께 호출된다. \n",
        "- collate 함수는 input data들을 하나의 batch로 생성하는 역할을 한다.\n"
      ],
      "metadata": {
        "id": "kSJV6T_LLVcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### custom collate function"
      ],
      "metadata": {
        "id": "N1li5ew9MX5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "\n",
        "  label_list, text_list = [], []\n",
        "\n",
        "  for (_text, _label) in batch:\n",
        "    label_list.append(_label)\n",
        "    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  \n",
        "  text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
        "\n",
        "  return text_list.to(device), label_list.to(device)"
      ],
      "metadata": {
        "id": "S1G0QvP4MbaL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 다양한 사이즈의 시퀀셜한 데이터를 collate할 때 torch.nn.utils.rnn.pad_sequence를 사용하여 padding을 줄 수 있다.\n",
        "\n",
        "- collate_fn의 input은 dataloader에 있는 배치 사이즈의 배치 데이터이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "GI-GgQF8N8oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_batch,shuffle=True)\n",
        "\n",
        "for x,y in dataloader:\n",
        "  print(x, \"Targets\", y, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90dZO-3iO56G",
        "outputId": "a1a8dad7-eb36-4378-bedd-55306bc2c124"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4, 10,  4,  5,  3, 48, 11],\n",
            "        [25,  1, 34,  0,  0,  0,  0]]) Targets tensor([0, 1]) \n",
            "\n",
            "tensor([[ 4, 10,  4,  5,  3, 39,  1, 54, 28,  0,  0],\n",
            "        [14, 52, 42, 50, 55, 35,  7, 57,  2, 19,  9]]) Targets tensor([1, 0]) \n",
            "\n",
            "tensor([[18, 29, 12, 31, 30, 38,  0,  0,  0],\n",
            "        [ 5,  3, 21, 17, 56, 16, 20,  2, 49]]) Targets tensor([1, 1]) \n",
            "\n",
            "tensor([[15, 40, 23, 24, 41],\n",
            "        [43,  8,  6, 13, 32]]) Targets tensor([0, 0]) \n",
            "\n",
            "tensor([[33,  9,  7, 51,  0],\n",
            "        [44,  1, 53, 45, 11]]) Targets tensor([0, 0]) \n",
            "\n",
            "tensor([[26,  6,  2, 36],\n",
            "        [46,  1,  2, 37]]) Targets tensor([0, 1]) \n",
            "\n",
            "tensor([[27,  8,  6,  3, 47,  1,  2, 22]]) Targets tensor([1]) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}